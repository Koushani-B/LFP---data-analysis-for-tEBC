# -*- coding: utf-8 -*-
"""Koushani_LFP_analysis (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mli1lcH14F3vC0xHGkWvH9-_lFiNsMbR
"""

!pip install cupy-cuda12x

#load google drive
from google.colab import drive

drive.mount('/content/gdrive')

#Importing libraries
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
from scipy import signal as scipy_signal
from scipy.stats import kruskal, mannwhitneyu
from scipy.ndimage import gaussian_filter

#Reading Data Files
def read_single_ncs(filepath):
    """Read Neuralynx .ncs file"""
    dt = np.dtype([('timestamp', np.uint64), ('channel', np.uint32),
                   ('sample_rate', np.uint32), ('n_valid', np.uint32),
                   ('samples', np.int16, 512)])

    with open(filepath, 'rb') as f:
        header = f.read(16384).decode('latin-1')
        fs = float([line.split()[-1] for line in header.split('\r\n')
                   if '-SamplingFrequency' in line][0])
        data = np.fromfile(f, dtype=dt)

    lfp = data['samples'].flatten()
    return {
        'lfp': lfp,
        'times': np.arange(len(lfp)) / fs,
        'fs': fs,
        'channel': os.path.basename(filepath).replace('.ncs', '')
    }

def load_multiple_sessions(base_path, session_folders):
    """Load LFP data"""
    session_dict = session_folders if isinstance(session_folders, dict) else {f: f for f in session_folders}
    all_data = []

    for session_id, folder_name in session_dict.items():
        session_path = os.path.join(base_path, folder_name)
        if not os.path.exists(session_path):
            print(f" Skipping: {session_path}")
            continue

        print(f"\n Loading: {session_id}")
        ncs_files = sorted([f for f in os.listdir(session_path) if f.endswith('.ncs')])

        for ncs_file in ncs_files:
            try:
                data = read_single_ncs(os.path.join(session_path, ncs_file))
                df = pd.DataFrame({
                    'time': data['times'], 'lfp': data['lfp'],
                    'channel': data['channel'], 'session': session_id, 'fs': data['fs']
                })
                all_data.append(df)
                print(f"   {data['channel']}: {len(data['lfp']):,} samples")
            except Exception as e:
                print(f"   {ncs_file}: {e}")

    if all_data:
        df_all = pd.concat(all_data, ignore_index=True)
        print(f"\n{'='*60}")
        print(f" Loaded {df_all['session'].nunique()} sessions, {df_all['channel'].nunique()} channels")
        return df_all
    return pd.DataFrame()

def read_neuralynx_events(filepath):
    """Read event file"""
    dt = np.dtype([('stx', np.int16), ('pkt_id', np.int16), ('pkt_data_size', np.int16),
                   ('timestamp', np.uint64), ('event_id', np.int16), ('ttl', np.int16),
                   ('crc', np.int16), ('dummy1', np.int16), ('dummy2', np.int16),
                   ('extra', np.int32, 8), ('event_string', 'S128')])

    with open(filepath, 'rb') as f:
        f.read(16384)
        events = np.fromfile(f, dtype=dt)

    df = pd.DataFrame({'timestamp': events['timestamp'], 'ttl': events['ttl']})
    if len(df) > 0:
        df['time_seconds'] = (df['timestamp'] - df['timestamp'].iloc[0]) / 1e6
    return df

def read_all_events(session_path):
    """Read all events"""
    nev_files = sorted([f for f in os.listdir(session_path) if f.endswith('.nev')])
    if not nev_files:
        return pd.DataFrame()

    all_events = []
    for nev_file in nev_files:
        try:
            df = read_neuralynx_events(os.path.join(session_path, nev_file))
            all_events.append(df)
            print(f"   {nev_file}: {len(df)} events")
        except Exception as e:
            print(f"   {nev_file}: {e}")

    return pd.concat(all_events, ignore_index=True).sort_values('timestamp').reset_index(drop=True) if all_events else pd.DataFrame()

#visualize LFP

def plot_raw_lfp_sample(df_all, session_id, regions, duration_sec=10, start_time=0, figsize=(16, 8)):
    """
    Plot raw LFP traces from all three brain regions

    Parameters:
    -----------
    df_all : DataFrame
        All LFP data
    session_id : str
        Which session to visualize
    regions : dict
        Region-to-channel mapping
    duration_sec : float
        How many seconds to display
    start_time : float
        Starting time in seconds
    figsize : tuple
        Figure size
    """
    n_regions = len(regions)
    fig, axes = plt.subplots(n_regions, 1, figsize=figsize, sharex=True)

    if n_regions == 1:
        axes = [axes]

    region_colors = {'Cerebellum': '#003f5c', 'Hippocampus': '#bc5090', 'ACC': '#ffa600'}

    print("\n Plotting raw LFP traces...")

    for idx, (region_name, channels) in enumerate(regions.items()):
        ax = axes[idx]

        # Get first channel for this region
        channel = channels[0]

        # Filter data for this channel and session
        lfp_data = df_all[(df_all['session'] == session_id) &
                         (df_all['channel'] == channel)].sort_values('time')

        if not lfp_data.empty:
            # Get time window
            time_mask = (lfp_data['time'] >= start_time) & (lfp_data['time'] <= start_time + duration_sec)
            segment = lfp_data[time_mask]

            if not segment.empty:
                # Plot LFP trace
                ax.plot(segment['time'].values, segment['lfp'].values,
                       color=region_colors.get(region_name, 'black'),
                       linewidth=0.5, alpha=0.8)

                # Formatting
                ax.set_ylabel(f'{region_name}\n({channel})\nVoltage (μV)',
                            fontsize=12, fontweight='bold',
                            color=region_colors.get(region_name, 'black'))
                ax.grid(True, alpha=0.3, linestyle='--')
                ax.spines['top'].set_visible(False)
                ax.spines['right'].set_visible(False)
                ax.spines['left'].set_linewidth(2)
                ax.spines['bottom'].set_linewidth(2)

                # Add statistics
                mean_lfp = np.mean(segment['lfp'].values)
                std_lfp = np.std(segment['lfp'].values)
                ax.text(0.02, 0.95, f'Mean={mean_lfp:.1f} μV\nSD={std_lfp:.1f} μV',
                       transform=ax.transAxes, fontsize=9,
                       verticalalignment='top',
                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

                print(f"  {region_name} ({channel}): {len(segment)} samples, Range=[{segment['lfp'].min():.1f}, {segment['lfp'].max():.1f}] μV")
        else:
            ax.text(0.5, 0.5, 'No data available',
                   ha='center', va='center', transform=ax.transAxes,
                   fontsize=14, style='italic', color='red')

    # X-axis label on bottom plot only
    axes[-1].set_xlabel('Time (seconds)', fontsize=13, fontweight='bold')

    fig.suptitle(f'Raw LFP Traces Across Brain Regions\nSession: {session_id}',
                fontsize=16, fontweight='bold', y=0.995)
    plt.tight_layout()
    plt.show()

#trial structure
def create_trial_structure(events_df, cs_ttl=8, us_ttl=16):
    """Create trials from events"""
    cs_events = events_df[events_df['ttl'] == cs_ttl].sort_values('time_seconds').reset_index(drop=True)
    us_events = events_df[events_df['ttl'] == us_ttl].sort_values('time_seconds').reset_index(drop=True)

    print(f"  CS events: {len(cs_events)}, US events: {len(us_events)}")

    trials = []
    for i in range(len(cs_events)):
        cs_time = cs_events.loc[i, 'time_seconds']
        is_cs_alone = ((i + 1) % 10 == 0)

        if is_cs_alone:
            us_time = np.nan
        else:
            us_cand = us_events[(us_events['time_seconds'] > cs_time) &
                               (us_events['time_seconds'] <= cs_time + 0.8)]
            us_time = us_cand.iloc[0]['time_seconds'] if len(us_cand) > 0 else np.nan

        trials.append({
            'trial_number': i + 1,
            'trial_type': 'cs_alone' if is_cs_alone else 'paired',
            'cs_onset_time': cs_time,
            'us_onset_time': us_time,
            'trial_start': cs_time - 0.2,
            'trial_end': cs_time + 1.0
        })

    return pd.DataFrame(trials)

def extract_trial_lfp(df_lfp, trials_df, channel, session_id):
    """Extract trial LFP"""
    lfp_data = df_lfp[(df_lfp['session'] == session_id) & (df_lfp['channel'] == channel)].sort_values('time')

    if lfp_data.empty:
        return []

    trial_data = []
    for _, trial in trials_df.iterrows():
        segment = lfp_data[(lfp_data['time'] >= trial['trial_start']) &
                          (lfp_data['time'] <= trial['trial_end'])].copy()
        if not segment.empty:
            trial_data.append({
                'trial_info': trial.to_dict(),
                'time': (segment['time'].values - trial['cs_onset_time']),
                'lfp': segment['lfp'].values,
                'fs': segment['fs'].iloc[0]
            })

    return trial_data

#compute power

def compute_power_across_trial(trial_data, freq_band, time_window=(0, 1000), z_score=True):
    """
    Compute z-scored power across trial

    Returns array of z-scored power values (one per trial)
    """
    baseline_power = []
    trial_power = []

    for trial in trial_data:
        time_ms = trial['time'] * 1000
        lfp = trial['lfp']
        fs = trial['fs']

        # Baseline for normalization
        baseline_mask = (time_ms >= -200) & (time_ms <= 0)
        baseline_signal = lfp[baseline_mask]

        if len(baseline_signal) > 10:
            try:
                freqs, psd = scipy_signal.welch(baseline_signal, fs, nperseg=min(256, len(baseline_signal)))
                band_mask = (freqs >= freq_band[0]) & (freqs <= freq_band[1])
                if np.sum(band_mask) > 0:
                    baseline_power.append(np.mean(psd[band_mask]))
            except:
                pass

        # Trial power
        trial_mask = (time_ms >= time_window[0]) & (time_ms <= time_window[1])
        trial_signal = lfp[trial_mask]

        if len(trial_signal) > 10:
            try:
                freqs, psd = scipy_signal.welch(trial_signal, fs, nperseg=min(512, len(trial_signal)))
                band_mask = (freqs >= freq_band[0]) & (freqs <= freq_band[1])
                if np.sum(band_mask) > 0:
                    trial_power.append(np.mean(psd[band_mask]))
            except:
                pass

    # Z-score
    trial_power = np.array(trial_power)

    if z_score and len(baseline_power) > 1:
        baseline_mean = np.mean(baseline_power)
        baseline_std = np.std(baseline_power)

        if baseline_std > 1e-10:
            trial_power = (trial_power - baseline_mean) / baseline_std

    return trial_power

#computing stats for not normal distribution

def compare_frequency_bands_across_regions(df_all, trials_df, regions, session_id, freq_bands):
    """
    Compare frequency bands across regions

    Tests both parametric (ANOVA) and non-parametric (Kruskal-Wallis)
    Checks normality to determine which test is more appropriate
    """
    from scipy.stats import shapiro, f_oneway

    region_band_data = {region: {band: [] for band in freq_bands.keys()}
                        for region in regions.keys()}



    for region_name, channels in regions.items():
        print(f"\n  {region_name}:")
        for channel in channels:
            trial_data = extract_trial_lfp(df_all, trials_df, channel, session_id)

            if trial_data:
                for band_name, freq_band in freq_bands.items():
                    power = compute_power_across_trial(trial_data, freq_band,
                                                       time_window=(0, 1000), z_score=True)
                    region_band_data[region_name][band_name] = np.array(power)
                    print(f"    {band_name}: n={len(power)}, Mean={np.mean(power):.3f}, Median={np.median(power):.3f}")

    # Test normality for each group

    print(" NORMALITY TESTS (Shapiro-Wilk)")

    print("If p > 0.05: data is normally distributed hence use ANOVA")
    print("If p < 0.05: data is NOT normal hence use Kruskal-Wallis")

    all_normal = True
    for band_name in freq_bands.keys():
        print(f"\n{band_name}:")
        for region in regions.keys():
            data = region_band_data[region][band_name]
            if len(data) >= 3:  # Need at least 3 samples for Shapiro-Wilk
                stat, p_val = shapiro(data)
                is_normal = p_val > 0.05
                all_normal = all_normal and is_normal
                status = " Normal" if is_normal else " NOT Normal"
                print(f"  {region}: W={stat:.3f}, p={p_val:.4f} {status}")

    # Check for extreme outliers

    print("  DATA QUALITY: Outlier Detection")


    for band_name in freq_bands.keys():
        outliers_found = False
        for region in regions.keys():
            data = region_band_data[region][band_name]
            if len(data) > 0:
                q1, q3 = np.percentile(data, [25, 75])
                iqr = q3 - q1
                outlier_threshold = q3 + 3 * iqr
                n_extreme = np.sum(data > outlier_threshold)

                if n_extreme > 0:
                    if not outliers_found:
                        print(f"\n{band_name}:")
                        outliers_found = True
                    print(f"  {region}: {n_extreme} extreme outliers (max={np.max(data):.1f})")
                    print(f"    Median={np.median(data):.2f}, Mean={np.mean(data):.2f}")

        if not outliers_found:
            print(f"\n{band_name}:  No extreme outliers")

    # Statistical tests
    results = []


    if all_normal:
        print(" PARAMETRIC ANOVA (data is normally distributed)")
    else:
        print(" KRUSKAL-WALLIS TEST (data is NOT normally distributed)")


    for band_name, freq_range in freq_bands.items():
        print(f"\n {band_name} ({freq_range[0]}-{freq_range[1]} Hz):")

        # Get data for all regions
        groups = [region_band_data[region][band_name] for region in regions.keys()
                  if len(region_band_data[region][band_name]) > 0]

        if len(groups) >= 2:
            # Both tests for comparison
            f_stat, p_anova = f_oneway(*groups)
            h_stat, p_kw = kruskal(*groups)

            # Determine which test to use based on normality
            if all_normal:
                primary_test = "ANOVA"
                primary_stat = f_stat
                primary_p = p_anova
                sig = '***' if p_anova < 0.001 else '**' if p_anova < 0.01 else '*' if p_anova < 0.05 else 'ns'
            else:
                primary_test = "Kruskal-Wallis"
                primary_stat = h_stat
                primary_p = p_kw
                sig = '***' if p_kw < 0.001 else '**' if p_kw < 0.01 else '*' if p_kw < 0.05 else 'ns'

            print(f"  {primary_test}: statistic={primary_stat:.3f}, p={primary_p:.4f} {sig}")
            print(f"  (Alternative test: {'KW' if all_normal else 'ANOVA'}: p={p_kw if all_normal else p_anova:.4f})")

            # Regional means
            for region in regions.keys():
                data = region_band_data[region][band_name]
                print(f"    {region}: Mean={np.mean(data):.3f}, Median={np.median(data):.3f}, SD={np.std(data):.3f}")

            results.append({
                'frequency_band': band_name,
                'freq_range': f"{freq_range[0]}-{freq_range[1]} Hz",
                'primary_test': primary_test,
                'statistic': primary_stat,
                'p_value': primary_p,
                'sig': sig,
                'F_stat': f_stat,
                'p_anova': p_anova,
                'H_stat': h_stat,
                'p_kruskal': p_kw,
                'Cerebellum_mean': np.mean(region_band_data['Cerebellum'][band_name]),
                'Hippocampus_mean': np.mean(region_band_data['Hippocampus'][band_name]),
                'ACC_mean': np.mean(region_band_data['ACC'][band_name])
            })

    return pd.DataFrame(results), region_band_data

def plot_frequency_bands_comparison_OPTION1(region_band_data, regions, freq_bands, figsize=(8, 10)):
    """
    Vertical stacked subplots with box plots
    One subplot per frequency band
    """
    n_bands = len(freq_bands)
    fig, axes = plt.subplots(n_bands, 1, figsize=figsize)

    if n_bands == 1:
        axes = [axes]

    region_names = list(regions.keys())
    colors = ['#003f5c', '#bc5090', '#ffa600']

    for idx, (band_name, freq_range) in enumerate(freq_bands.items()):
        ax = axes[idx]

        # Get data for all regions in this band
        data_list = [region_band_data[region][band_name] for region in region_names]

        # Create box plots
        positions = [1, 2, 3]  # Explicit positions for the 3 regions
        bp = ax.boxplot(data_list, positions=positions, patch_artist=True,
                       widths=0.5, showfliers=True, notch=False,
                       boxprops=dict(linewidth=2),
                       whiskerprops=dict(linewidth=2),
                       capprops=dict(linewidth=2),
                       medianprops=dict(linewidth=0.5, color='black'))

        # Color boxes by region
        for i, box in enumerate(bp['boxes']):
            box.set_facecolor(colors[i])
            box.set_alpha(0.8)
            box.set_edgecolor('black')

        # Formatting
        ax.set_xticks(positions)
        ax.set_xticklabels(region_names, fontsize=13, fontweight='bold')
        ax.set_ylabel('Z-scored Power', fontsize=13, fontweight='bold')
        ax.set_title(f"{band_name} ({freq_range[0]}-{freq_range[1]} Hz)",
                    fontsize=14, fontweight='bold', pad=10, loc='left')
        ax.grid(True, alpha=0.3, axis='y', linestyle='--')
        ax.axhline(0, color='gray', linestyle='-', linewidth=1.5, alpha=0.7)

        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        ax.spines['left'].set_linewidth(2)
        ax.spines['bottom'].set_linewidth(2)

        # Set reasonable y-limits to see the box structure
        # Exclude extreme outliers for y-axis calculation
        all_data = np.concatenate(data_list)
        q1, q3 = np.percentile(all_data, [25, 75])
        iqr = q3 - q1
        # Show up to 3*IQR beyond the quartiles
        y_min = max(q1 - 3*iqr, np.min(all_data))
        y_max = min(q3 + 3*iqr, np.percentile(all_data, 99))  # Cap at 99th percentile
        ax.set_ylim(y_min - 1, y_max + 1)


def plot_frequency_bands_comparison_OPTION2(region_band_data, regions, freq_bands, figsize=(14, 10)):
    """
    Violin plots (shows full distribution)
    Alternative to box plots with density estimation
    """
    n_bands = len(freq_bands)
    fig, axes = plt.subplots(n_bands, 1, figsize=figsize, sharex=True)

    if n_bands == 1:
        axes = [axes]

    region_names = list(regions.keys())
    colors = ['#003f5c', '#bc5090', '#ffa600']

    for idx, (band_name, freq_range) in enumerate(freq_bands.items()):
        ax = axes[idx]

        data_list = [region_band_data[region][band_name] for region in region_names]

        # Create violin plots
        parts = ax.violinplot(data_list, positions=range(len(region_names)),
                             showmeans=True, showmedians=True, widths=0.7)

        # Color violins
        for i, pc in enumerate(parts['bodies']):
            pc.set_facecolor(colors[i])
            pc.set_alpha(0.7)
            pc.set_edgecolor('black')
            pc.set_linewidth(1.5)

        # Style the other elements
        for partname in ('cbars', 'cmins', 'cmaxes', 'cmedians', 'cmeans'):
            if partname in parts:
                vp = parts[partname]
                vp.set_edgecolor('black')
                vp.set_linewidth(2)

        # Formatting
        ax.set_xticks(range(len(region_names)))
        ax.set_xticklabels(region_names if idx == n_bands - 1 else [],
                          fontsize=13, fontweight='bold')
        ax.set_ylabel('Z-scored Power', fontsize=13, fontweight='bold')
        ax.set_title(f"{band_name} ({freq_range[0]}-{freq_range[1]} Hz)",
                    fontsize=14, fontweight='bold', pad=10, loc='left')
        ax.grid(True, alpha=0.3, axis='y', linestyle='--')
        ax.axhline(0, color='gray', linestyle='-', linewidth=1.5, alpha=0.7)

        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        ax.spines['left'].set_linewidth(2)
        ax.spines['bottom'].set_linewidth(2)

    fig.suptitle('Spectral Power Distribution (Violin Plots)\n(Z-scored, 0-1000ms post-CS)',
                fontsize=16, fontweight='bold', y=0.995)
    plt.tight_layout()
    plt.show()

def plot_frequency_bands_comparison(region_band_data, regions, freq_bands, figsize=None):
    """
    Main plotting function - BOX PLOTS
    """
    # visualization style
    plot_frequency_bands_comparison_OPTION1(region_band_data, regions, freq_bands)

#spectogram


def plot_power_spectra(df_all, trials_df, regions, session_id, freq_range=(0, 50),
                       trial_type='all', smooth_sigma=2.0, figsize=(18, 10)):
    """Time-frequency spectrograms"""
    n_regions = len(regions)
    fig, axes = plt.subplots(n_regions, 1, figsize=figsize, sharex=True, sharey=True)

    if n_regions == 1:
        axes = [axes]

    region_colors = {'Cerebellum': '#003f5c', 'Hippocampus': '#bc5090', 'ACC': '#ffa600'}

    if trial_type != 'all':
        trials_filtered = trials_df[trials_df['trial_type'] == trial_type]
    else:
        trials_filtered = trials_df

    for row, (region_name, channels) in enumerate(regions.items()):
        ax = axes[row]
        all_specs = []

        for channel in channels:
            trial_data = extract_trial_lfp(df_all, trials_filtered, channel, session_id)
            if trial_data:
                lfps = [t['lfp'] for t in trial_data if len(t['lfp']) == len(trial_data[0]['lfp'])]
                if lfps:
                    avg_lfp = np.mean(lfps, axis=0)
                    fs = trial_data[0]['fs']
                    time_rel = trial_data[0]['time']

                    f, t, Sxx = scipy_signal.spectrogram(avg_lfp, fs,
                                                         nperseg=512,
                                                         noverlap=480,
                                                         scaling='density')

                    Sxx_db = 10 * np.log10(Sxx + 1e-10)
                    all_specs.append(Sxx_db)

        if all_specs:
            avg_spec = np.mean(all_specs, axis=0)
            avg_spec_smooth = gaussian_filter(avg_spec, sigma=smooth_sigma)
            t_aligned = (t + time_rel[0]) * 1000
            freq_mask = (f >= freq_range[0]) & (f <= freq_range[1])

            im = ax.pcolormesh(t_aligned, f[freq_mask], avg_spec_smooth[freq_mask, :],
                              shading='gouraud', cmap='jet',
                              vmin=np.percentile(avg_spec_smooth[freq_mask, :], 5),
                              vmax=np.percentile(avg_spec_smooth[freq_mask, :], 95))

            ax.axvline(0, color='white', linestyle='--', linewidth=3, alpha=0.9, label='CS onset')
            ax.axvline(250, color='cyan', linestyle=':', linewidth=2, alpha=0.8, label='CS offset')

            if trial_type != 'cs_alone':
                ax.axvline(750, color='yellow', linestyle='--', linewidth=3, alpha=0.9, label='US onset')

            ax.axvspan(-200, 0, alpha=0.08, color='gray', zorder=0)
            ax.axvspan(0, 250, alpha=0.08, color='blue', zorder=0)
            ax.axvspan(250, 750, alpha=0.04, color='yellow', zorder=0)
            if trial_type != 'cs_alone':
                ax.axvspan(750, 775, alpha=0.12, color='red', zorder=0)

            ax.set_ylabel(f'{region_name}\nFrequency (Hz)',
                        fontsize=13, fontweight='bold',
                        color=region_colors.get(region_name, 'black'))

            if row == 0:
                ax.legend(loc='upper right', fontsize=10, framealpha=0.9)

            if row == n_regions - 1:
                ax.set_xlabel('Time from CS onset (ms)', fontsize=13, fontweight='bold')

            ax.tick_params(labelsize=11)
            ax.spines['top'].set_linewidth(2)
            ax.spines['right'].set_linewidth(2)
            ax.spines['left'].set_linewidth(2)
            ax.spines['bottom'].set_linewidth(2)
            ax.set_xlim(-200, 1000)

    plt.subplots_adjust(right=0.88)
    cbar_ax = fig.add_axes([0.91, 0.15, 0.02, 0.7])
    cbar = fig.colorbar(im, cax=cbar_ax, orientation='vertical')
    cbar.set_label('Power (dB)', fontsize=13, fontweight='bold', rotation=270, labelpad=20)
    cbar.ax.tick_params(labelsize=11)

    fig.suptitle(f'Time-Frequency Spectrograms ({trial_type} trials)',
                fontsize=17, fontweight='bold', y=0.98)
    plt.show()

# configuration



print("CONFIGURATION")


base_path = '/content/gdrive/MyDrive/Code_analysis/Data_ephys/r6627'
sessions = ['KB_R6627__S27_trace250_500_2k']

regions = {
    'Cerebellum': ['CSC3'],
    'Hippocampus': ['CSC12'],
    'ACC': ['CSC10']
}

freq_bands = {
    'Theta': (4, 12),
    'Beta': (12, 30),
    'Gamma': (30, 50)
}

print(f"\nRegions: {list(regions.keys())}")
print(f"Frequency bands: {list(freq_bands.keys())}")

# Run Analysis


print("STEP 1: LOAD DATA")

df_all = load_multiple_sessions(base_path, sessions)


print("STEP 2: CREATE TRIALS")

first_session = df_all['session'].unique()[0]
session_path = os.path.join(base_path, first_session)
events_df = read_all_events(session_path)
trials_df = create_trial_structure(events_df, cs_ttl=8, us_ttl=16)

print(f"\n {len(trials_df)} trials ({len(trials_df[trials_df['trial_type']=='paired'])} paired)")


print("STEP 3: COMPARE FREQUENCY BANDS ACROSS REGIONS")


anova_results, region_band_data = compare_frequency_bands_across_regions(
    df_all, trials_df, regions, first_session, freq_bands
)


print(" SUMMARY TABLE")

print(anova_results.to_string(index=False))

print("\n Creating ploT")
plot_frequency_bands_comparison(region_band_data, regions, freq_bands)



print("\n Paired trials:")
plot_power_spectra(df_all, trials_df, regions, first_session, (0, 50), 'paired')

print("\n CS-alone trials:")
plot_power_spectra(df_all, trials_df, regions, first_session, (0, 50), 'cs_alone')




print(" VISUALIZE RAW LFP DATA")


print("\n Raw continuous LFP (10 seconds):")
plot_raw_lfp_sample(df_all, first_session, regions, duration_sec=10, start_time=0)


print("ANALYSIS COMPLETE")
